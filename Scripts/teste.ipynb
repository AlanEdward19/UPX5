{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratar CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def corrigir_diferenca_tempo(dataframe):\n",
    "    dataframe['datetime'] = pd.to_datetime(dataframe['time'], unit='s')\n",
    "\n",
    "    time_diff = dataframe['datetime'].diff()\n",
    "    time_diff = time_diff.fillna(pd.Timedelta(seconds=0))\n",
    "    time_diff = time_diff.apply(lambda x: pd.Timedelta(minutes=1) if x.total_seconds() == 1 else x)\n",
    "\n",
    "    dataframe['datetime'] = dataframe['datetime'] + time_diff.cumsum()\n",
    "\n",
    "    dataframe['datetime'] = dataframe['datetime'].apply(lambda dt: dt.replace(second=0))\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def timestamp_para_datahora(timestamp):\n",
    "    datahora = datetime.datetime.fromtimestamp(timestamp)\n",
    "    return datahora\n",
    "\n",
    "def merge_dataframe(df, group_size=60):\n",
    "    # Cria o dataframe auxiliar\n",
    "    df_merged = pd.DataFrame()\n",
    "\n",
    "    # Loop pelos grupos de tamanho \"group_size\"\n",
    "    for i in range(0, len(df), group_size):\n",
    "        # Seleciona o grupo atual\n",
    "        df_group = df.iloc[i:i+group_size,:]\n",
    "\n",
    "        # Loop pelas colunas do grupo\n",
    "        for col in df_group.columns:\n",
    "\n",
    "            # Verifica se a coluna é a datetime\n",
    "            if col == 'datetime':\n",
    "                # Armazena o valor da primeira linha da coluna\n",
    "                col_value = df_group[col].iloc[0]\n",
    "\n",
    "                # Ajusta apenas a hora mantendo os minutos\n",
    "                col_value = col_value.replace(minute=0, second=0)\n",
    "\n",
    "            else:\n",
    "                # Armazena o valor da primeira linha da coluna\n",
    "                col_value = df_group[col].iloc[0]\n",
    "\n",
    "                # Loop pelas linhas da coluna\n",
    "                for j in range(1, len(df_group)):\n",
    "\n",
    "                    # Verifica se o valor atual é maior ou menor que o valor armazenado\n",
    "                    if df_group[col].iloc[j] > col_value:\n",
    "                        # Soma a diferença na variável armazenada\n",
    "                        col_value += df_group[col].iloc[j] - col_value\n",
    "                        \n",
    "                    elif df_group[col].iloc[j] < col_value:\n",
    "                        # Soma a diferença na variável armazenada\n",
    "                        col_value -= col_value - df_group[col].iloc[j]\n",
    "\n",
    "            # Insere a coluna e valor no dataframe auxiliar\n",
    "            df_merged.loc[i//group_size, col] = col_value\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "\n",
    "def formatar_dataframe(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Converter a coluna \"time\" para valores numéricos e filtrar os valores nulos e não numéricos\n",
    "    dataframe['time'] = pd.to_numeric(dataframe['time'], errors='coerce')\n",
    "    dataframe = dataframe[~dataframe['time'].isna()]\n",
    "\n",
    "    # Converter a coluna \"time\" para timestamp e criar a coluna \"datetime\"\n",
    "    dataframe = corrigir_diferenca_tempo(dataframe)\n",
    "\n",
    "    # Apagar a coluna \"time\", \"summary\", \"icon\", \"cloudCover\"\n",
    "    dataframe = dataframe.drop(columns=['time', 'summary', 'icon', 'cloudCover'])\n",
    "\n",
    "    # Ordena alfabeticamente as colunas\n",
    "    dataframe = dataframe.sort_index(axis=1)\n",
    "\n",
    "    return merge_dataframe(dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar CSV Tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath = '../Files/HomeCTratado.csv'\n",
    "dataframe = formatar_dataframe(pd.read_csv('../Files/HomeC.csv', delimiter=',', low_memory=False))\n",
    "\n",
    "dataframe.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "\n",
    "#Abrir CSV ja tratado\n",
    "df = pd.read_csv('../Files/HomeCTratado.csv', delimiter=',', low_memory=False)\n",
    "\n",
    "#Colunas que não envolvem KW\n",
    "exclude_columns = ['apparentTemperature','datetime','dewPoint','humidity','precipIntensity','precipProbability','pressure','temperature','visibility','windBearing','windSpeed']\n",
    "\n",
    "#Salvar todos os dados do dataframe menos as colunas acima\n",
    "X = df[[column for column in list(df.columns) if column not in exclude_columns]]\n",
    "\n",
    "#Definir padrões pro algoritmo\n",
    "isolation_forest = IsolationForest(n_estimators=100, contamination='auto')\n",
    "\n",
    "#Treinar o algoritmo\n",
    "isolation_forest.fit(X)\n",
    "\n",
    "#Achar as anomalias\n",
    "y_pred = isolation_forest.predict(X)\n",
    "\n",
    "#Adicionar nova coluna dizendo se é ou não anomalia\n",
    "df['anomaly'] = y_pred\n",
    "\n",
    "#Dataframe somente com anomalias\n",
    "anomaly = df.loc[df['anomaly'] == -1]\n",
    "\n",
    "anomaly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
